
@misc{hamdan2024sparsemambareinforcingcontrollability,
      title={Sparse Mamba: Reinforcing Controllability In Structural State Space Models}, 
      author={Emadeldeen Hamdan and Hongyi Pan and Ahmet Enis Cetin},
      year={2024},
      eprint={2409.00563},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.00563}, 
}

@misc{arora2023theoryemergencecomplexskills,
      title={A Theory for Emergence of Complex Skills in Language Models}, 
      author={Sanjeev Arora and Anirudh Goyal},
      year={2023},
      eprint={2307.15936},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2307.15936}, 
}
@misc{lin2022teachingmodelsexpressuncertainty,
      title={Teaching Models to Express Their Uncertainty in Words}, 
      author={Stephanie Lin and Jacob Hilton and Owain Evans},
      year={2022},
      eprint={2205.14334},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2205.14334}, 
}
@misc{ding2023longnetscalingtransformers1000000000,
      title={LongNet: Scaling Transformers to 1,000,000,000 Tokens}, 
      author={Jiayu Ding and Shuming Ma and Li Dong and Xingxing Zhang and Shaohan Huang and Wenhui Wang and Nanning Zheng and Furu Wei},
      year={2023},
      eprint={2307.02486},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.02486}, 
}

@misc{liu2023lostmiddlelanguagemodels,
      title={Lost in the Middle: How Language Models Use Long Contexts}, 
      author={Nelson F. Liu and Kevin Lin and John Hewitt and Ashwin Paranjape and Michele Bevilacqua and Fabio Petroni and Percy Liang},
      year={2023},
      eprint={2307.03172},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.03172}, 
}

@misc{wu2022memorizingtransformers,
      title={Memorizing Transformers}, 
      author={Yuhuai Wu and Markus N. Rabe and DeLesley Hutchins and Christian Szegedy},
      year={2022},
      eprint={2203.08913},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2203.08913}, 
}

@article{Besta_2024,
   title={Graph of Thoughts: Solving Elaborate Problems with Large Language Models},
   volume={38},
   ISSN={2159-5399},
   url={http://dx.doi.org/10.1609/aaai.v38i16.29720},
   DOI={10.1609/aaai.v38i16.29720},
   number={16},
   journal={Proceedings of the AAAI Conference on Artificial Intelligence},
   publisher={Association for the Advancement of Artificial Intelligence (AAAI)},
   author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and Hoefler, Torsten},
   year={2024},
   month=mar, pages={17682–17690} 
}


@misc{zhou2023leasttomostpromptingenablescomplex,
      title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models}, 
      author={Denny Zhou and Nathanael Schärli and Le Hou and Jason Wei and Nathan Scales and Xuezhi Wang and Dale Schuurmans and Claire Cui and Olivier Bousquet and Quoc Le and Ed Chi},
      year={2023},
      eprint={2205.10625},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2205.10625}, 
}

@article{Wei2022ChainOT,
  title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
  author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Ed Huai-hsin Chi and F. Xia and Quoc Le and Denny Zhou},
  journal={ArXiv},
  year={2022},
  volume={abs/2201.11903},
  url={https://api.semanticscholar.org/CorpusID:246411621}
}