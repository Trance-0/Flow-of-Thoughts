\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{delétang2024languagemodelingcompression}
\citation{liu2023lostmiddlelanguagemodels}
\citation{Wei2022ChainOT}
\citation{Besta_2024}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Chain-of-thoughts}{1}{subsection.2.1}\protected@file@percent }
\citation{lin2022teachingmodelsexpressuncertainty}
\citation{weng2023largelanguagemodelsbetter}
\citation{wu2022memorizingtransformers}
\citation{asai2023selfraglearningretrievegenerate}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Graph-of-thoughts}{2}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Express uncertainty}{2}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Self-verification}{2}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Memorizing Transformers and Self-Reflective Retrieval-Augmented Generation (SELF-RAG)}{2}{subsection.2.5}\protected@file@percent }
\citation{weng2023largelanguagemodelsbetter}
\@writefile{toc}{\contentsline {section}{\numberline {3}Framework design}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Preprocessing}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Generating methods}{3}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Self-verification and refining}{3}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Aggregation}{3}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Novelty of the solution}{3}{subsection.3.5}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Flow of thoughts($P,Q$)}}{4}{algorithm.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:cap}{{1}{4}{Flow of thoughts($P,Q$)}{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Efficiency}{4}{subsection.3.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiment results}{4}{section.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Flow of Thoughts framework using graph visualization, the pink nodes are the nodes from the knowledge graph or definition of the problem, the yellow nodes are generated by the LLM, the purple nodes are refinement of the solution generated by the LLM. In the final layer, the LLM will aggregate the solution and generate the final answer (the cyan node)}}{5}{figure.caption.2}\protected@file@percent }
\newlabel{fig:flow_of_thoughts}{{1}{5}{Flow of Thoughts framework using graph visualization, the pink nodes are the nodes from the knowledge graph or definition of the problem, the yellow nodes are generated by the LLM, the purple nodes are refinement of the solution generated by the LLM. In the final layer, the LLM will aggregate the solution and generate the final answer (the cyan node)}{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Other framework structure defined in the experiment, only use for reference, detailed structure can be found in each run of the experiment}}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:sorting_results}{{2}{5}{Other framework structure defined in the experiment, only use for reference, detailed structure can be found in each run of the experiment}{figure.caption.3}{}}
\citation{lai2017large}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Sorting}{6}{subsection.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Average number of incorrect responses in sorting 32 intergers}}{6}{table.caption.4}\protected@file@percent }
\newlabel{tab:sorting_results}{{1}{6}{Average number of incorrect responses in sorting 32 intergers}{table.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Set Intersection}{6}{subsection.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Average number of incorrect responses in set intersection}}{6}{table.caption.5}\protected@file@percent }
\newlabel{tab:set_intersection_results}{{2}{6}{Average number of incorrect responses in set intersection}{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Reading Comprehension}{6}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Analysis}{6}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Method generation}{6}{subsection.5.1}\protected@file@percent }
\citation{qin2023toolllmfacilitatinglargelanguage}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Score of the reading comprehension task on RACE-min dataset}}{7}{table.caption.6}\protected@file@percent }
\newlabel{tab:reading_comprehension_results}{{3}{7}{Score of the reading comprehension task on RACE-min dataset}{table.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Self-checking process}{7}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Limitations and potential future work}{7}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Approach generation}{7}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}High expense for thoughts generation}{7}{subsection.6.2}\protected@file@percent }
\citation{lin2022teachingmodelsexpressuncertainty}
\bibdata{references}
\bibcite{asai2023selfraglearningretrievegenerate}{{1}{}{{}}{{}}}
\bibcite{Besta_2024}{{2}{}{{}}{{}}}
\bibcite{delétang2024languagemodelingcompression}{{3}{}{{}}{{}}}
\bibcite{lai2017large}{{4}{}{{}}{{}}}
\bibcite{lin2022teachingmodelsexpressuncertainty}{{5}{}{{}}{{}}}
\bibcite{liu2023lostmiddlelanguagemodels}{{6}{}{{}}{{}}}
\bibcite{qin2023toolllmfacilitatinglargelanguage}{{7}{}{{}}{{}}}
\bibcite{Wei2022ChainOT}{{8}{}{{}}{{}}}
\bibcite{weng2023largelanguagemodelsbetter}{{9}{}{{}}{{}}}
\bibcite{wu2022memorizingtransformers}{{10}{}{{}}{{}}}
\bibstyle{plain}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Flexibility for Divide and Conquer approach}{8}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Potential improvements that can be made}{8}{subsection.6.4}\protected@file@percent }
\newlabel{sec:future_work_self_generation}{{6.4}{8}{Potential improvements that can be made}{subsection.6.4}{}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\contentsline {section}{\numberline {7}Appendix}{9}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Prompts used in solving the problem}{9}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Sorting}{9}{subsubsection.7.1.1}\protected@file@percent }
\newlabel{sec:appendix_sorting}{{7.1.1}{9}{Sorting}{subsubsection.7.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}Set Intersection}{9}{subsubsection.7.1.2}\protected@file@percent }
\newlabel{sec:appendix_set_intersection}{{7.1.2}{9}{Set Intersection}{subsubsection.7.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.3}Reading Comprehension}{9}{subsubsection.7.1.3}\protected@file@percent }
\newlabel{sec:appendix_reading_comprehension}{{7.1.3}{9}{Reading Comprehension}{subsubsection.7.1.3}{}}
\gdef \@abspage@last{9}
