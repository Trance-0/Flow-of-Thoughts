\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{delétang2024languagemodelingcompression}
\citation{liu2023lostmiddlelanguagemodels}
\citation{Wei2022ChainOT}
\citation{Besta_2024}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Chain-of-thoughts}{1}{subsection.2.1}\protected@file@percent }
\citation{lin2022teachingmodelsexpressuncertainty}
\citation{weng2023largelanguagemodelsbetter}
\citation{wu2022memorizingtransformers}
\citation{asai2023selfraglearningretrievegenerate}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Graph-of-thoughts}{2}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Express uncertainty}{2}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Self-verification}{2}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Memorizing Transformers and Self-Reflective Retrieval-Augmented Generation (SELF-RAG)}{2}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Framework design}{3}{section.3}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Flow of thoughts($P,Q$)}}{3}{algorithm.1}\protected@file@percent }
\newlabel{alg:cap}{{1}{3}{Framework design}{algorithm.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Novelty of the solution}{3}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Flow of Thoughts framework using graph visualization, the pink nodes are the nodes from the knowledge graph or definition of the problem, the yellow nodes are generated by the LLM, the purple nodes are refinement of the solution generated by the LLM. In the final layer, the LLM will aggregate the solution and generate the final answer (the cyan node)}}{4}{figure.1}\protected@file@percent }
\newlabel{fig:flow_of_thoughts}{{1}{4}{Flow of Thoughts framework using graph visualization, the pink nodes are the nodes from the knowledge graph or definition of the problem, the yellow nodes are generated by the LLM, the purple nodes are refinement of the solution generated by the LLM. In the final layer, the LLM will aggregate the solution and generate the final answer (the cyan node)}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Efficiency}{4}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiment results}{4}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Sorting}{4}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Set Intersection}{4}{subsection.4.2}\protected@file@percent }
\citation{lai2017large}
\citation{qin2023toolllmfacilitatinglargelanguage}
\bibdata{references}
\bibcite{asai2023selfraglearningretrievegenerate}{{1}{}{{}}{{}}}
\bibcite{Besta_2024}{{2}{}{{}}{{}}}
\bibcite{delétang2024languagemodelingcompression}{{3}{}{{}}{{}}}
\bibcite{lai2017large}{{4}{}{{}}{{}}}
\bibcite{lin2022teachingmodelsexpressuncertainty}{{5}{}{{}}{{}}}
\bibcite{liu2023lostmiddlelanguagemodels}{{6}{}{{}}{{}}}
\bibcite{qin2023toolllmfacilitatinglargelanguage}{{7}{}{{}}{{}}}
\bibcite{Wei2022ChainOT}{{8}{}{{}}{{}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Reading Comprehension}{5}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Analysis}{5}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Limitations and potential future work}{5}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Approach generation}{5}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}High expense for graph generation}{5}{subsection.6.2}\protected@file@percent }
\bibcite{weng2023largelanguagemodelsbetter}{{9}{}{{}}{{}}}
\bibcite{wu2022memorizingtransformers}{{10}{}{{}}{{}}}
\bibstyle{plain}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\contentsline {section}{\numberline {7}Appendix}{6}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Prompts used in solving the problem}{6}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Sorting}{6}{subsubsection.7.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.2}Set Intersection}{6}{subsubsection.7.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.3}Reading Comprehension}{6}{subsubsection.7.1.3}\protected@file@percent }
\gdef \@abspage@last{6}
